<html>

<head>
</head>

<body>
<script src="p5/p5.js"></script>
<script src="p5/addons/p5.sound.js"></script>
<script language="javascript" type="text/javascript" src="p5/addons/p5.dom.js"></script>

<script src="Tone.js"></script>
<script src="obj.js"></script>
<script src="analyzer.js"></script>
  <script src="recorder.js"></script>

<h1 onclick="record()">start recording</h1>
<h1 onclick="stopRecord()">stop recording</h1>
<audio controls></audio>



<button onclick="startRecording(this);">record</button>
<button onclick="stopRecording(this);" disabled>stop</button>

<h2>Recordings</h2>
<ul id="recordingslist"></ul>

<h2>Log</h2>
<pre id="log"></pre>

<script>
function __log(e, data) {
		log.innerHTML += "\n" + e + " " + (data || '');
}

var audio_context;
var recorder;

function startUserMedia() {
		var input = actx.createMediaStreamSource(dest.stream);
		__log('Media stream created.');

		// Uncomment if you want the audio to feedback directly
		//input.connect(audio_context.destination);
		//__log('Input connected to audio context destination.');

		recorder = new Recorder(input);
		__log('Recorder initialised.');
}

function startRecording(button) {
		recorder && recorder.record();
		button.disabled = true;
		button.nextElementSibling.disabled = false;
		__log('Recording...');
}

function stopRecording(button) {
		recorder && recorder.stop();
		button.disabled = true;
		button.previousElementSibling.disabled = false;
		__log('Stopped recording.');

		// create WAV download link using audio data blob
		createDownloadLink();

}

function createDownloadLink() {
		recorder && recorder.exportWAV(function(blob) {
				var url = URL.createObjectURL(blob);
				var li = document.createElement('li');
				var au = document.createElement('audio');
				var hf = document.createElement('a');

				au.controls = true;
				au.src = url;
				hf.href = url;
				hf.download = new Date().toISOString() + '.wav';
				hf.innerHTML = hf.download;
				li.appendChild(au);
				li.appendChild(hf);
				recordingslist.appendChild(li);
		});
}

window.onload = function init() {
		try {
				// webkit shim
				window.AudioContext = window.AudioContext || window.webkitAudioContext;
				navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia;
				window.URL = window.URL || window.webkitURL;

				audio_context = new AudioContext;
				__log('Audio context set up.');
				__log('navigator.getUserMedia ' + (navigator.getUserMedia ? 'available.' : 'not present!'));
		} catch (e) {
				alert('No web audio support in this browser!');
		}

	startUserMedia();
};
</script>






<script>
/*
console.clear();

// UPDATE: there is a problem in chrome with starting audio context
//  before a user gesture. This fixes it.
var started = false; //true when we start recoding
function record(){
	console.log(actx);

  if (started) return;
  started = true;
  const audio = document.querySelector('audio');
  const chunks = [];
		const config = {
		    type: 'audio/wav',
		    mimeType: 'audio/wav',
		    numberOfAudioChannels: 2
		};

		recorder.start();

  recorder.ondataavailable = evt => chunks.push(evt.data);
  recorder.onstop = evt => {
    let blob = new Blob(chunks, config);
    audio.src = URL.createObjectURL(blob);
  };

  Tone.Transport.start();
}

function stopRecord(){

	 recorder.stop();
}*/

</script>




</body>
</html>
